# ğŸš— Vision-Guided Smart Car System

<div align="center">

![Smart Car](https://img.shields.io/badge/Smart%20Car-ESP32-blue?style=for-the-badge)
![Computer Vision](https://img.shields.io/badge/Computer%20Vision-YOLO11-green?style=for-the-badge)
![Hand Gesture](https://img.shields.io/badge/Hand%20Gesture-Recognition-orange?style=for-the-badge)
![Person Tracking](https://img.shields.io/badge/Person-Tracking-red?style=for-the-badge)
![Real Time](https://img.shields.io/badge/Real%20Time-Processing-yellow?style=for-the-badge)

[![GitHub Stars](https://img.shields.io/github/stars/menuka400/vision-guided-smart-car-system?style=social)](https://github.com/menuka400/vision-guided-smart-car-system)
[![License](https://img.shields.io/badge/License-MIT-blue.svg)](LICENSE)
[![Python](https://img.shields.io/badge/Python-3.8+-blue.svg)](https://python.org)
[![ESP32](https://img.shields.io/badge/ESP32-Compatible-green.svg)](https://espressif.com)

**ğŸ¯ An intelligent autonomous car system that responds to hand gestures and actively tracks people using advanced computer vision**

*Control your car with simple hand gestures and let it follow you around automatically!*

[âœ¨ Features](#-features) â€¢ [ğŸš€ Quick Start](#-quick-start) â€¢ [ğŸ“¦ Installation](#-installation) â€¢ [ğŸ® Usage](#-usage) â€¢ [ğŸ”§ Hardware](#-hardware) â€¢ [ğŸ“¹ Demo](#-demo) â€¢ [ğŸ¤ Contributing](#-contributing)

</div>

---

## ğŸŒŸ Features

<table>
<tr>
<td width="50%">

### ğŸ–ï¸ **Hand Gesture Control**
- ğŸ«· **Left Hand Raised**: Car moves forward
- ğŸ«¸ **Right Hand Raised**: Car moves backward
- ğŸ›‘ **Both Hands**: Emergency stop
- ğŸ¯ Real-time gesture recognition using YOLO11-pose
- âš¡ Ultra-fast response time (<100ms)

</td>
<td width="50%">

### ğŸ¯ **Intelligent Person Tracking**
- ğŸ”„ **Auto-Orient**: Car automatically adjusts position to keep person centered
- ğŸ”’ **Person Lock**: Locks onto the first person who raises their hand
- ğŸ“ˆ **Trail Visualization**: Shows movement history with colored trails
- ğŸ”„ **Smart Recovery**: Handles person loss and re-detection

</td>
</tr>
<tr>
<td>

### ğŸ“¹ **Advanced Computer Vision**
- ğŸ§  **YOLO11x-pose**: State-of-the-art pose estimation
- ğŸª **Real-time Processing**: Optimized for live camera feeds
- ğŸ¨ **Visual Feedback**: Rich on-screen indicators and status displays
- ğŸ“Š **Performance Monitoring**: FPS counter and system stats

</td>
<td>

### ğŸš— **Smart Car Features**
- ğŸ”§ **ESP32-based**: WiFi-enabled microcontroller
- âš™ï¸ **4-Motor Drive**: Precise movement control with PWM
- ğŸŒ **HTTP API**: RESTful communication
- ğŸ›¡ï¸ **Emergency Stop**: Safety-first design
- âš¡ **Synchronized Motors**: All motors start together at max speed

</td>
</tr>
</table>

---

## ï¿½ Quick Start

### ğŸ¬ **Get Started in 3 Steps!**

```bash
# 1ï¸âƒ£ Clone the repository
git clone https://github.com/menuka400/vision-guided-smart-car-system.git
cd vision-guided-smart-car-system

# 2ï¸âƒ£ Install dependencies
pip install -r requirements.txt

# 3ï¸âƒ£ Run the system
python main_with_car.py
```

> ğŸ¯ **Pro Tip**: Make sure your ESP32 is connected to WiFi and update the IP address in the configuration!

---

## ğŸ“¦ Installation

### ğŸ”§ **Prerequisites**
- ![Python](https://img.shields.io/badge/Python-3.8+-blue.svg) Python 3.8+
- ![OpenCV](https://img.shields.io/badge/OpenCV-4.5+-green.svg) OpenCV 4.5+
- ![PyTorch](https://img.shields.io/badge/PyTorch-1.9+-orange.svg) PyTorch 1.9+
- ![ESP32](https://img.shields.io/badge/ESP32-WiFi-red.svg) ESP32 with WiFi capability

### ğŸ“¥ **Step-by-Step Installation**

#### 1. **Clone Repository**
```bash
git clone https://github.com/menuka400/vision-guided-smart-car-system.git
cd vision-guided-smart-car-system
```

#### 2. **Install Python Dependencies**
```bash
# Install all required packages
pip install -r requirements.txt

# Or install individually
pip install opencv-python ultralytics requests PyYAML
```

#### 3. **Configure the System**
```yaml
# Edit config.yaml to match your setup
wifi:
  ssid: "YourWiFiNetwork"
  password: "YourWiFiPassword"
  
car:
  ip: "192.168.1.112"  # Update with your ESP32 IP
  
vision:
  camera_index: 0  # Change if using external camera
```

#### 4. **Flash ESP32 Firmware**
1. Open `smartcar.cpp` in Arduino IDE
2. Update WiFi credentials
3. Flash to your ESP32
4. Note the assigned IP address

#### 5. **Download Models (Automatic)**
The system will automatically download required models on first run:
- âœ… `yolo11x-pose.pt` - YOLO11 pose estimation model
- âœ… Models are cached for faster startup

---

## ğŸ® Usage

### ğŸ¯ **Basic Operation**

```python
# Start the vision system
python main_with_car.py

# Alternative: Start with specific camera
python main_with_car.py --camera 1

# Run with video file
python main_with_car.py --video path/to/video.mp4
```

### âš™ï¸ **Configuration Management**

The system uses a centralized `config.yaml` file for easy customization:

```yaml
# Just edit and restart - no code changes needed!
vision:
  confidence_threshold: 0.5
  max_fps: 30
  display_trails: true
  
car:
  max_speed: 255
  turn_speed: 180
  motor_directions: [1, 1, 1, -1]  # Correct motor directions
  
system:
  debug_mode: false
  log_level: "INFO"
```

### ğŸ® **Interactive Controls**

<div align="center">

| Key | Function | Description |
|-----|----------|-------------|
| `q` | ğŸšª Quit | Exit application |
| `r` | ğŸ”„ Reset | Reset tracking system |
| `t` | ğŸ¯ Toggle | Toggle person tracking on/off |
| `s` | âš™ï¸ Settings | Adjust tracking sensitivity |
| `c` | ğŸ”— Connect | Test car connection |
| `d` | ğŸ› Debug | Toggle debug mode |

</div>

### ğŸ­ **Hand Gesture Commands**

<div align="center">

| Gesture | Action | Visual Indicator |
|---------|---------|------------------|
| ğŸ«· Left Hand Up | â¬†ï¸ Move Forward | Green Arrow |
| ğŸ«¸ Right Hand Up | â¬‡ï¸ Move Backward | Red Arrow |
| ğŸ™Œ Both Hands Up | ğŸ›‘ Emergency Stop | Red Circle |
| ğŸ‘ No Hands | ğŸ”„ Auto-Track | Blue Target |

</div>

---

## ğŸ”§ Hardware Requirements

### ğŸš— **Smart Car Components**

<div align="center">

| Component | Specification | Purpose |
|-----------|---------------|---------|
| ğŸ§  **Microcontroller** | ESP32 DevKit | Main processing unit |
| âš™ï¸ **Motors** | 4x DC motors + drivers | Movement control |
| ğŸ”‹ **Power** | 7.4V LiPo battery | Power supply |
| ğŸ“¶ **WiFi** | Built-in ESP32 WiFi | Communication |
| ğŸ”Œ **Connections** | Jumper wires | Hardware assembly |

</div>

### ğŸ“ **Pin Configuration**

```cpp
// Motor Pin Mapping (ESP32)
struct MotorPins {
    // Front Right Motor
    int FR_IN1 = 14, FR_IN2 = 12;
    
    // Back Right Motor  
    int BR_IN1 = 13, BR_IN2 = 4;
    
    // Front Left Motor
    int FL_IN1 = 27, FL_IN2 = 26;
    
    // Back Left Motor
    int BL_IN1 = 25, BL_IN2 = 33;
};
```

### ğŸ’» **Computer Requirements**

<div align="center">

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| ğŸ“¹ **Camera** | USB webcam | HD webcam (1080p) |
| ğŸ–¥ï¸ **CPU** | Intel i5 / AMD Ryzen 5 | Intel i7 / AMD Ryzen 7 |
| ğŸ§  **RAM** | 8GB | 16GB |
| ğŸ® **GPU** | Integrated graphics | NVIDIA GTX 1060+ |
| ğŸ’¾ **Storage** | 2GB free space | 5GB free space |

</div>

### ğŸ”§ **Assembly Guide**

1. **Motor Installation**: Mount 4 DC motors to car chassis
2. **ESP32 Mounting**: Secure ESP32 to central position
3. **Wiring**: Connect motors to ESP32 using pin configuration above
4. **Power**: Connect 7.4V battery to motor drivers
5. **Testing**: Upload firmware and test motor rotation

---

## ğŸ“¹ Demo

### ğŸ¥ **See It In Action!**

<div align="center">

| Demo Type | Description |
|-----------|-------------|
| ğŸ® **Hand Gesture Control** | Control car movement with simple hand gestures |
| ğŸ¯ **Person Tracking** | Car automatically follows you around |
| ğŸ”„ **Auto-Orientation** | Car adjusts to keep you centered |
| ğŸ›‘ **Emergency Stop** | Instant stop for safety |

*ğŸ“¹ Demo videos coming soon!*

</div>

### ğŸª **Live Demo Features**

- âœ… Real-time hand gesture recognition
- âœ… Smooth person tracking with trail visualization
- âœ… Motor synchronization and direction correction
- âœ… WiFi connectivity status indicators
- âœ… Performance monitoring (FPS, latency)

---

## ğŸ“ Project Structure

```
vision-guided-smart-car-system/
â”œâ”€â”€ ğŸ“„ main_with_car.py              # ğŸš€ Main application
â”œâ”€â”€ ğŸ“„ car_controller.py             # ğŸš— Smart car communication
â”œâ”€â”€ ğŸ“„ smartcar.cpp                  # ğŸ”§ ESP32 firmware
â”œâ”€â”€ ğŸ“„ config.yaml                   # âš™ï¸ Configuration file
â”œâ”€â”€ ğŸ“„ config_loader.py              # ğŸ”§ Configuration manager
â”œâ”€â”€ ğŸ“„ generate_arduino_config.py    # ğŸ”„ Arduino config generator
â”œâ”€â”€ ğŸ“„ arduino_config.h              # ğŸ”§ Auto-generated Arduino config
â”œâ”€â”€ ğŸ“„ requirements.txt              # ğŸ“¦ Python dependencies
â”œâ”€â”€ ğŸ“„ yolo11x-pose.pt              # ğŸ§  YOLO11 pose model
â”œâ”€â”€ ğŸ“„ README.md                     # ğŸ“– Project documentation
â”œâ”€â”€ ğŸ“„ CONFIG_GUIDE.md               # ğŸ“‹ Configuration guide
â””â”€â”€ ğŸ“ __pycache__/                  # ğŸ—‚ï¸ Python cache files
```

### ğŸ” **Key Files Explained**

- ğŸ¯ **`main_with_car.py`**: Core vision system with YOLO pose detection
- ğŸš— **`car_controller.py`**: HTTP communication with ESP32
- ğŸ”§ **`smartcar.cpp`**: Arduino firmware with motor control
- âš™ï¸ **`config.yaml`**: Centralized configuration management
- ğŸ”„ **`config_loader.py`**: Python configuration utilities

---

## ğŸ§  How It Works

### ğŸ”„ **System Architecture**

<div align="center">

```mermaid
graph TD
    A[ğŸ“¹ Camera Feed] --> B[ğŸ§  YOLO11 Pose Detection]
    B --> C[ğŸ–ï¸ Hand Gesture Recognition]
    B --> D[ğŸ¯ Person Tracking]
    C --> E[ğŸš— Car Movement Control]
    D --> F[ğŸ“ Auto-Orientation]
    E --> G[ğŸ“¡ WiFi Communication]
    F --> G
    G --> H[ğŸ”§ ESP32 Controller]
    H --> I[âš™ï¸ Motor Control]
    I --> J[ğŸš— Smart Car Movement]
```

</div>

### 1. **ğŸ” Person Detection & Pose Estimation**
```python
# YOLO11 detects people and extracts 17 keypoints
results = self.yolo_model(frame)
for result in results:
    keypoints = result.keypoints.xy[0]  # Get keypoints
    # Extract key body parts
    left_wrist = keypoints[9]
    right_wrist = keypoints[10]
    left_elbow = keypoints[7]
    right_elbow = keypoints[8]
```

### 2. **ğŸ–ï¸ Hand Gesture Recognition Algorithm**
```python
# Smart hand detection logic
def detect_raised_hand(wrist, elbow, shoulder):
    """
    Detects raised hand using vertical relationship
    Hand is raised when: wrist_y < elbow_y < shoulder_y
    """
    if wrist[1] < elbow[1] < shoulder[1]:
        return True
    return False
```

### 3. **ğŸ¯ Person Tracking System**
```python
# Auto-orientation logic
def calculate_orientation(person_x, frame_center_x, threshold=50):
    """
    Determines car orientation based on person position
    """
    if person_x < frame_center_x - threshold:
        return "track_left"
    elif person_x > frame_center_x + threshold:
        return "track_right"
    else:
        return "track_center"
```

### 4. **ğŸš— Car Control & Communication**
```python
# HTTP communication with ESP32
def send_command(self, command):
    """
    Sends movement commands to ESP32 via HTTP POST
    """
    try:
        response = requests.post(
            f"http://{self.car_ip}/control",
            json={"command": command},
            timeout=0.5
        )
        return response.status_code == 200
    except:
        return False
```

### 5. **âš™ï¸ Motor Control (ESP32)**
```cpp
// Synchronized motor control with direction correction
void startAllMotorsForward() {
    // Apply direction correction for each motor
    for (int i = 0; i < 4; i++) {
        int correctedSpeed = PWM_MAX * motorDirections[i];
        rotateMotor(i, correctedSpeed);
    }
}
```

---

## ğŸ¯ Key Features Explained

### ğŸ”’ **Smart Person Locking**
- ğŸ¯ System waits for a person to raise their hand before tracking
- ğŸ” Once locked, follows only that specific person
- â° Automatic unlock after 10 seconds of person absence
- ğŸ”„ Re-lock capability for continuous operation

### ğŸ® **Dual Control System**
- ğŸ–ï¸ **Hand Gestures**: Control car movement (forward/backward/stop)
- ğŸ“ **Position Tracking**: Control car orientation (left/right/center)
- ğŸ¤ Both systems work simultaneously for smooth operation
- âš¡ Ultra-responsive with <100ms latency

### ğŸ¨ **Visual Feedback System**
- ğŸ“Š Real-time status indicators
- ğŸ¯ Tracking zone visualization
- â¡ï¸ Movement direction arrows
- ğŸ”— Connection status displays
- ğŸ“ˆ Performance metrics (FPS, response time)

### ğŸ›¡ï¸ **Safety Features**
- ğŸš¨ Emergency stop on connection loss
- ğŸ”„ Automatic reset on person loss
- âš™ï¸ Configurable tracking sensitivity
- ğŸ® Manual override controls
- ğŸ›‘ Hardware-level emergency stop

---

## ğŸ”§ Troubleshooting

### ğŸ”— **Connection Issues**

<div align="center">

| Problem | Solution | Command |
|---------|----------|---------|
| ğŸš« Car not responding | Check IP address | `ping 192.168.1.112` |
| ğŸ“¶ WiFi connection lost | Restart ESP32 | Press reset button |
| ğŸ”Œ Network issues | Check same WiFi network | `ipconfig` |

</div>

### ğŸ¯ **Performance Optimization**

```python
# ğŸš€ Speed optimizations
# Use nano model for faster inference
self.yolo_model = YOLO('yolo11n-pose.pt')

# Reduce frame size for better performance
frame = cv2.resize(frame, (640, 480))

# Adjust confidence threshold
if conf > 0.3:  # Lower = more detections, higher = more accurate
```

### ğŸ› **Common Issues & Solutions**

<div align="center">

| Issue | Cause | Solution |
|-------|-------|----------|
| ğŸ–ï¸ Hand detection failing | Poor lighting | Improve lighting conditions |
| ğŸ¯ Tracking lag | Low performance | Use smaller model or reduce FPS |
| ğŸ‘¤ Person loss | Fast movement | Adjust tracking sensitivity |
| ğŸ”„ Motors not synchronized | Direction issues | Check motor direction config |
| ğŸ“¶ Connection timeout | Network latency | Increase timeout values |

</div>

### ğŸ”§ **Debug Mode**

```python
# Enable debug mode for detailed logging
python main_with_car.py --debug

# Check configuration
python -c "import config_loader; print(config_loader.ConfigLoader().get_all())"

# Test car connection
python -c "from car_controller import CarController; CarController().test_connection()"
```

---

## ğŸ¤ Contributing

<div align="center">

**ğŸ‰ Contributions are welcome! Help make this project even better!**

[![Contributors Welcome](https://img.shields.io/badge/Contributors-Welcome-brightgreen?style=for-the-badge)](https://github.com/menuka400/vision-guided-smart-car-system/contribute)
[![Good First Issues](https://img.shields.io/badge/Good%20First-Issues-blue?style=for-the-badge)](https://github.com/menuka400/vision-guided-smart-car-system/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22)

</div>

### ğŸš€ **How to Contribute**

1. **ğŸ´ Fork** the repository
2. **ğŸŒŸ Create** a feature branch (`git checkout -b feature/AmazingFeature`)
3. **âœ¨ Commit** your changes (`git commit -m 'Add some AmazingFeature'`)
4. **ğŸ“¤ Push** to the branch (`git push origin feature/AmazingFeature`)
5. **ğŸ”„ Open** a Pull Request

### ğŸ¯ **Areas for Improvement**

<div align="center">

| Category | Ideas | Priority |
|----------|-------|----------|
| ğŸ® **Control** | Voice commands, Mobile app | ğŸ”¥ High |
| ğŸ§  **Intelligence** | Multi-person tracking, Obstacle detection | ğŸ”¥ High |
| ğŸš— **Hardware** | Sensor integration, Better motors | ğŸŸ¡ Medium |
| ğŸ“± **Interface** | Web dashboard, Remote control | ğŸŸ¡ Medium |
| ğŸ”§ **DevOps** | CI/CD, Automated testing | ğŸŸ¢ Low |

</div>

### ğŸ’¡ **Feature Requests**

Have an idea? We'd love to hear it! 

- ğŸ™ï¸ **Voice Control**: "Car, follow me!"
- ğŸ“± **Mobile App**: Control from your phone
- ğŸ¯ **Multiple People**: Track multiple people simultaneously
- ğŸš§ **Obstacle Detection**: Avoid obstacles automatically
- ğŸ—ºï¸ **Route Planning**: Plan and follow routes
- ğŸ”Š **Sound Effects**: Add fun sound effects
- ğŸ“Š **Analytics**: Movement history and statistics

### ğŸ† **Contributors**

<div align="center">

*Be the first to contribute and get your name here!*

[![GitHub Contributors](https://contrib.rocks/image?repo=menuka400/vision-guided-smart-car-system)](https://github.com/menuka400/vision-guided-smart-car-system/graphs/contributors)

</div>

### ğŸ“‹ **Development Guidelines**

- ğŸ§ª **Testing**: Write tests for new features
- ğŸ“ **Documentation**: Update documentation for changes
- ğŸ¨ **Code Style**: Follow PEP 8 for Python code
- ğŸ”„ **Compatibility**: Ensure ESP32 compatibility
- ğŸ›¡ï¸ **Safety**: Always consider safety implications

---

## ğŸ“„ License

<div align="center">

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg?style=for-the-badge)](https://opensource.org/licenses/MIT)

*Feel free to use, modify, and distribute this project!*

</div>

---

## ğŸ™ Acknowledgments

<div align="center">

**ğŸ‰ Special thanks to these amazing projects and communities:**

[![Ultralytics](https://img.shields.io/badge/Ultralytics-YOLO11-blue?style=for-the-badge)](https://ultralytics.com)
[![OpenCV](https://img.shields.io/badge/OpenCV-Computer%20Vision-green?style=for-the-badge)](https://opencv.org)
[![ESP32](https://img.shields.io/badge/ESP32-Espressif-red?style=for-the-badge)](https://espressif.com)
[![Arduino](https://img.shields.io/badge/Arduino-Community-orange?style=for-the-badge)](https://arduino.cc)

</div>

- ğŸ§  **Ultralytics Team** for the incredible YOLO11 implementation
- ğŸ“¹ **OpenCV Community** for computer vision tools and libraries
- ğŸ”§ **ESP32 Community** for hardware support and documentation
- ğŸ¯ **Arduino Community** for the development platform
- ğŸŒŸ **GitHub Community** for hosting and collaboration tools

---

## ğŸŒŸ Star History

<div align="center">

[![Star History Chart](https://api.star-history.com/svg?repos=menuka400/vision-guided-smart-car-system&type=Date)](https://star-history.com/#menuka400/vision-guided-smart-car-system&Date)

</div>

---

## ğŸ“ Support

<div align="center">

**Need help? Have questions? We're here to help!**

[![Issues](https://img.shields.io/badge/Issues-Ask%20Questions-blue?style=for-the-badge)](https://github.com/menuka400/vision-guided-smart-car-system/issues)
[![Discussions](https://img.shields.io/badge/Discussions-Join%20Community-green?style=for-the-badge)](https://github.com/menuka400/vision-guided-smart-car-system/discussions)

ğŸ“§ **Email**: menuka400@gmail.com
ğŸ™ **GitHub**: [@menuka400](https://github.com/menuka400)

</div>

---

<div align="center">

**â­ If you found this project helpful, please give it a star! â­**

**ğŸ”„ Share with your friends and help grow the community!**

---

*Made with â¤ï¸ by [Menuka](https://github.com/menuka400) | Built with ğŸ¤– AI assistance*

**ğŸš— Happy Building! ğŸš—**

</div>
